{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: __Alexandre Antar__\n",
    "\n",
    "Nome: __Gabriel de Araujo Alves__\n",
    "\n",
    "Nome: __Renato Fanfrachini Falcao__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\users\\gabri\\anaconda3\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: wordcloud in c:\\users\\gabri\\anaconda3\\lib\\site-packages (1.8.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from wordcloud) (3.3.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from wordcloud) (8.0.1)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from wordcloud) (1.19.2)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2020.6.20)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Requirement already satisfied: six in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji wordcloud\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from emoji import UNICODE_EMOJI\n",
    "import emoji\n",
    "import functools\n",
    "import operator\n",
    "import nltk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\gabri\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\projeto1-Cdados#\\Project1\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'brahma.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @sophiaecris: @marianaa2mari foi vcs crlh !...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@moraesbrunita pelo visto na mamadeira j√° era ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@purosucodosurto o cara n√£o tem um pau tem um ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gente vcs que t√£o em home office a mais tempo ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @luciusnaweb: eu depois de dois lat√µes de b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relevancia\n",
       "0  rt @sophiaecris: @marianaa2mari foi vcs crlh !...           0\n",
       "1  @moraesbrunita pelo visto na mamadeira j√° era ...           0\n",
       "2  @purosucodosurto o cara n√£o tem um pau tem um ...           0\n",
       "3  gente vcs que t√£o em home office a mais tempo ...           1\n",
       "4  rt @luciusnaweb: eu depois de dois lat√µes de b...           0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#base de treinamento\n",
    "train = pd.read_excel(filename, sheet_name = 'Treinamento')\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@elissanmanoel t√£o costurando brahma ? hahaha ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt @nayaralucas11: era s√≥ uma praia e brahma t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arrumando meu guarda roupa eis que encontro um...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>desceu foi whisky misturado c brahma kkkkkkkkk...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @carolaguiarcm: hj eu s√≥ queria estar numa ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Relevancia\n",
       "0  @elissanmanoel t√£o costurando brahma ? hahaha ...           0\n",
       "1  rt @nayaralucas11: era s√≥ uma praia e brahma t...           0\n",
       "2  arrumando meu guarda roupa eis que encontro um...           0\n",
       "3  desceu foi whisky misturado c brahma kkkkkkkkk...           0\n",
       "4  rt @carolaguiarcm: hj eu s√≥ queria estar numa ...           0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#base de teste\n",
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @sophiaecris: @marianaa2mari foi vcs crlh !...</td>\n",
       "      <td>N√£o relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@moraesbrunita pelo visto na mamadeira j√° era ...</td>\n",
       "      <td>N√£o relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@purosucodosurto o cara n√£o tem um pau tem um ...</td>\n",
       "      <td>N√£o relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gente vcs que t√£o em home office a mais tempo ...</td>\n",
       "      <td>Relevante positiva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @luciusnaweb: eu depois de dois lat√µes de b...</td>\n",
       "      <td>N√£o relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>acho q vou beber uma hj, desde domingo sem beb...</td>\n",
       "      <td>Relevante negativa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento          Relevancia\n",
       "0  rt @sophiaecris: @marianaa2mari foi vcs crlh !...       N√£o relevante\n",
       "1  @moraesbrunita pelo visto na mamadeira j√° era ...       N√£o relevante\n",
       "2  @purosucodosurto o cara n√£o tem um pau tem um ...       N√£o relevante\n",
       "3  gente vcs que t√£o em home office a mais tempo ...  Relevante positiva\n",
       "4  rt @luciusnaweb: eu depois de dois lat√µes de b...       N√£o relevante\n",
       "5  acho q vou beber uma hj, desde domingo sem beb...  Relevante negativa"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transformando variavel Relevancia em categ√≥rica\n",
    "train['Relevancia'] = train['Relevancia'].astype('category')\n",
    "\n",
    "train['Relevancia'].cat.categories = ['Relevante negativa', 'N√£o relevante', 'Relevante positiva']\n",
    "train.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separando o data frame por relev√¢ncia do tweet\n",
    "nao_relevante=train[train.Relevancia=='N√£o relevante']\n",
    "relevante_positivo=train[train.Relevancia=='Relevante positiva']\n",
    "relevante_negativo=train[train.Relevancia=='Relevante negativa']\n",
    "classifica=[nao_relevante,relevante_positivo,relevante_negativo]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uma lista de strings para aferir a probabilidade posteriormente,n√£o necessariamente ser√° usada\n",
    "classifica_nao_relevante=str(list(classifica[0].Treinamento.values))\n",
    "classifica_positivo=str(list(classifica[1].Treinamento.values))\n",
    "classifica_negativo=str(list(classifica[2].Treinamento.values))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "O produto escolhido foi a cerveja Brahma, uma marca nacional e bem popular de cerveja e a classifica√ß√£o dos tweets foram feitos da seguinte forma:\n",
    "\n",
    "* -1 : Relevante negativo -> Essa classifica√ß√£o se refere aos tweets que mecionavam o a marca de cerveja de forma negativa, seja com reclama√ß√µes acerca do produto ou associando a marca √† alguma experi√™ncia ruim.\n",
    "* 0 : Irrelevante -> Essa classifica√ß√£o se refere aos tweets que mecionavam o a marca de cerveja de forma neutra, sem reclama√ß√µes ou elogios ao produto ou que n√£o se referiram √† cerveja.\n",
    "* 1 : Relevante positivo -> Essa classifica√ß√£o se refere aos tweets que mecionavam o a marca de cerveja de forma positiva, seja com elogios acerca do produto ou associando a marca √† alguma experi√™ncia boa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limpeza de mensagens em rela√ß√£o a pontua√ß√£o\n",
    "def cleanup_tweet(text):\n",
    "    punctuation = '[\\-/!.:?;,''\"@]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    text_subbed = re.sub(' +', ' ', text_subbed)\n",
    "    text_subbed = emoji.get_emoji_regexp().split(text_subbed)\n",
    "    separate = [text.split() for text in text_subbed]\n",
    "    text_subbed = functools.reduce(operator.concat, separate)\n",
    "    return text_subbed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remo√ß√£o de outros items que n√£o contar√£o para as relev√¢ncias\n",
    "def remove_outros(items):\n",
    "    i=0\n",
    "    while(i<len(items)):\n",
    "        # Limpa '\\n'\n",
    "        items[i] = items[i].lower().replace('[\\n]', '')\n",
    "        \n",
    "        # Remove 'rt' de retweets\n",
    "        if items[i][0:2] == 'rt':\n",
    "            items[i] = items[i][3:]\n",
    "        \n",
    "        # Remove links\n",
    "        elif items[i][:4] == 'http':\n",
    "            del items[i]\n",
    "        i+=1\n",
    "            \n",
    "        \n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gabri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Remove 'stopwords' (preposi√ß√µes, artigos etc.) dos tweets\n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "stopwords.append('')\n",
    "\n",
    "# Define fun√ß√£o que aplica remo√ß√£o\n",
    "def remove_stopwords(lista):\n",
    "    filtrada = lista[:]     \n",
    "    for palavra in lista: \n",
    "          if palavra in stopwords: \n",
    "                filtrada.remove(palavra)               \n",
    "    return filtrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#twt=cada tweet\n",
    "#aplica todas as fun√ß√µes anteriores para limpar as frases\n",
    "def limpos(classificador):\n",
    "    lis=[]\n",
    "    for twt in classificador.Treinamento:\n",
    "        lis.append(remove_stopwords(remove_outros(cleanup_tweet(twt))))\n",
    "    return lis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevancia</th>\n",
       "      <th>Treinamento_limpo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @sophiaecris: @marianaa2mari foi vcs crlh !...</td>\n",
       "      <td>N√£o relevante</td>\n",
       "      <td>sophiaecris, marianaa2mari, vcs, crlh, boa, br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@moraesbrunita pelo visto na mamadeira j√° era ...</td>\n",
       "      <td>N√£o relevante</td>\n",
       "      <td>moraesbrunita, visto, mamadeira, boa, brahma, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@purosucodosurto o cara n√£o tem um pau tem um ...</td>\n",
       "      <td>N√£o relevante</td>\n",
       "      <td>purosucodosurto, cara, pau, lat√£o, brahma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gente vcs que t√£o em home office a mais tempo ...</td>\n",
       "      <td>Relevante positiva</td>\n",
       "      <td>gente, vcs, t√£o, home, office, tempo, ok, mand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @luciusnaweb: eu depois de dois lat√µes de b...</td>\n",
       "      <td>N√£o relevante</td>\n",
       "      <td>luciusnaweb, dois, lat√µes, brahma, bem, assim,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento          Relevancia  \\\n",
       "0  rt @sophiaecris: @marianaa2mari foi vcs crlh !...       N√£o relevante   \n",
       "1  @moraesbrunita pelo visto na mamadeira j√° era ...       N√£o relevante   \n",
       "2  @purosucodosurto o cara n√£o tem um pau tem um ...       N√£o relevante   \n",
       "3  gente vcs que t√£o em home office a mais tempo ...  Relevante positiva   \n",
       "4  rt @luciusnaweb: eu depois de dois lat√µes de b...       N√£o relevante   \n",
       "\n",
       "                                   Treinamento_limpo  \n",
       "0  sophiaecris, marianaa2mari, vcs, crlh, boa, br...  \n",
       "1  moraesbrunita, visto, mamadeira, boa, brahma, ...  \n",
       "2          purosucodosurto, cara, pau, lat√£o, brahma  \n",
       "3  gente, vcs, t√£o, home, office, tempo, ok, mand...  \n",
       "4  luciusnaweb, dois, lat√µes, brahma, bem, assim,...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplica limpeza nas s√©ries de cada classifica√ß√£o\n",
    "limpeza_tweets = [limpos(classifica[0]), limpos(classifica[1]),limpos(classifica[2])]\n",
    "\n",
    "# Limpa dados de treino\n",
    "limpeza = limpos(train)\n",
    "\n",
    "# Aplica listagem das palavras dos dados de treino\n",
    "for i in range(len(limpeza)):\n",
    "    limpeza[i] = ', '.join(limpeza[i])\n",
    "\n",
    "# Cria coluna com tweets j√° limpos\n",
    "train['Treinamento_limpo'] = limpeza\n",
    "\n",
    "\n",
    "\n",
    "train.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2¬∞ ETAPA\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "Agora com os dados limpos ,o objetivo e ensinar o classificador de acordo com as porbabilidades de cada palavra apresentada para cada s√©rie de relev√¢ncia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1327"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#value_counts em rela√ß√£o aos tweets irrelevantes,assim o pd_series afere todas as probabilidades por palavra nessa s√©rie\n",
    "n_rel=train[train.Relevancia=='N√£o relevante']\n",
    "n_rel1=n_rel.Treinamento_limpo\n",
    "lista1=[]\n",
    "for tweet in n_rel1:\n",
    "    for palavra in tweet.split(','):\n",
    "        lista1.append(palavra)\n",
    "serie_n_rel=pd.Series(lista1).value_counts(True)\n",
    "tot_n_rel=len(serie_n_rel)\n",
    "tot_n_rel\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1108"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#value_counts em rela√ß√£o aos tweets relevantes positivos,assim o pd_series afere todas as probabilidades por palavra nessa s√©rie\n",
    "rel_pos=train[train.Relevancia=='Relevante positiva']\n",
    "rel_pos1=rel_pos.Treinamento_limpo\n",
    "lista2=[]\n",
    "for tweet in rel_pos1:\n",
    "    for palavra in tweet.split(','):\n",
    "        lista2.append(palavra)\n",
    "serie_pos=pd.Series(lista2).value_counts(True)\n",
    "tot_pos=len(serie_pos)\n",
    "tot_pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " brahma       0.097166\n",
       "brahma        0.024291\n",
       " ü§§            0.020243\n",
       " dor          0.020243\n",
       " dia          0.016194\n",
       "                ...   \n",
       " geladinha    0.004049\n",
       " √±            0.004049\n",
       " hj           0.004049\n",
       " est√°gio      0.004049\n",
       " cacete       0.004049\n",
       "Length: 170, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##value_counts em rela√ß√£o aos tweets relevantes negativos,assim o pd_series afere todas as probabilidades por palavra nessa s√©rie\n",
    "rel_neg=train[train.Relevancia=='Relevante negativa']\n",
    "rel_neg1=rel_neg.Treinamento_limpo\n",
    "lista3=[]\n",
    "for tweet in rel_neg1:\n",
    "    for palavra in tweet.split(','):\n",
    "        lista3.append(palavra)\n",
    "serie_neg=pd.Series(lista3).value_counts(True)\n",
    "tot_neg=len(serie_neg)\n",
    "tot_neg\n",
    "serie_neg\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lista4=[list(serie_n_rel.index),list(serie_pos.index),list(serie_neg.index)]\n",
    "lista5=[list(serie_n_rel.values),list(serie_pos.values),list(serie_neg.values)]\n",
    "\n",
    "probs=[]\n",
    "for i in range(len(lista4)):\n",
    "    dicio = {}\n",
    "    for j in range(len(lista4[i])):\n",
    "        dicio[lista4[i][j]]=lista5[i][j]\n",
    "    probs.append(pd.Series(dicio))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "# # probs.append(pd.Series(dicio))\n",
    "# # lista5[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista para as palavras n√£o repetidas\n",
    "def repetidas(lista1, lista2,lista3):\n",
    "    qtd = []\n",
    "    for tweet in lista1:\n",
    "        for palavra in tweet:\n",
    "            if palavra not in qtd:\n",
    "                qtd.append(palavra)                \n",
    "    for tweet in lista2:\n",
    "        for palavra in tweet:\n",
    "            if palavra not in qtd:\n",
    "                qtd.append(palavra)\n",
    "    for tweet in lista3:\n",
    "        for palavra in tweet:\n",
    "            if palavra not in qtd:\n",
    "                qtd.append(palavra)\n",
    "    return qtd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2169"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retorna o total de palavras n√£o repetidas em relacao as tr√™s classifica√ß√µes\n",
    "tol = (serie_n_rel + serie_pos + serie_neg).index.nunique()\n",
    "tol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevancia</th>\n",
       "      <th>Pr√© Processado</th>\n",
       "      <th>Naive Bayes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@elissanmanoel t√£o costurando brahma ? hahaha ...</td>\n",
       "      <td>N√£o relevante</td>\n",
       "      <td>[elissanmanoel, t√£o, costurando, brahma, hahah...</td>\n",
       "      <td>Relevante negativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt @nayaralucas11: era s√≥ uma praia e brahma t...</td>\n",
       "      <td>N√£o relevante</td>\n",
       "      <td>[nayaralucas11, praia, brahma, trincando]</td>\n",
       "      <td>Relevante negativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arrumando meu guarda roupa eis que encontro um...</td>\n",
       "      <td>N√£o relevante</td>\n",
       "      <td>[arrumando, guarda, roupa, eis, encontro, ling...</td>\n",
       "      <td>Relevante negativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>desceu foi whisky misturado c brahma kkkkkkkkk...</td>\n",
       "      <td>N√£o relevante</td>\n",
       "      <td>[desceu, whisky, misturado, c, brahma, kkkkkkk...</td>\n",
       "      <td>Relevante negativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @carolaguiarcm: hj eu s√≥ queria estar numa ...</td>\n",
       "      <td>N√£o relevante</td>\n",
       "      <td>[carolaguiarcm, hj, queria, estar, mesa, skol,...</td>\n",
       "      <td>Relevante negativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>v√≥ beber brahma fodaze</td>\n",
       "      <td>N√£o relevante</td>\n",
       "      <td>[v√≥, beber, brahma, fodaze]</td>\n",
       "      <td>Relevante negativa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste     Relevancia  \\\n",
       "0  @elissanmanoel t√£o costurando brahma ? hahaha ...  N√£o relevante   \n",
       "1  rt @nayaralucas11: era s√≥ uma praia e brahma t...  N√£o relevante   \n",
       "2  arrumando meu guarda roupa eis que encontro um...  N√£o relevante   \n",
       "3  desceu foi whisky misturado c brahma kkkkkkkkk...  N√£o relevante   \n",
       "4  rt @carolaguiarcm: hj eu s√≥ queria estar numa ...  N√£o relevante   \n",
       "5                             v√≥ beber brahma fodaze  N√£o relevante   \n",
       "\n",
       "                                      Pr√© Processado         Naive Bayes  \n",
       "0  [elissanmanoel, t√£o, costurando, brahma, hahah...  Relevante negativa  \n",
       "1          [nayaralucas11, praia, brahma, trincando]  Relevante negativa  \n",
       "2  [arrumando, guarda, roupa, eis, encontro, ling...  Relevante negativa  \n",
       "3  [desceu, whisky, misturado, c, brahma, kkkkkkk...  Relevante negativa  \n",
       "4  [carolaguiarcm, hj, queria, estar, mesa, skol,...  Relevante negativa  \n",
       "5                        [v√≥, beber, brahma, fodaze]  Relevante negativa  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def limpando(tweet):\n",
    "    limpo = remove_stopwords(remove_outros(cleanup_tweet(str(tweet))))\n",
    "    return limpo\n",
    "\n",
    "test_tweets = []\n",
    "for tweet in test['Teste']:\n",
    "    test_tweets.append(limpando(tweet))\n",
    "\n",
    "# Cria coluna de pr√© processados nos dados de teste\n",
    "series_test = pd.Series(test_tweets)\n",
    "test['Pr√© Processado'] = series_test\n",
    "\n",
    "#substitui a relevancia de numeros para categorias\n",
    "test['Relevancia'] = test['Relevancia'].astype('category')\n",
    "\n",
    "test['Relevancia'].cat.categories = ['Relevante negativa', 'N√£o relevante', 'Relevante positiva']\n",
    "test.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #limpeza dos tweets do teste\n",
    "# def limpando(tweet):\n",
    "#     limpo = remove_stopwords(remove_outros(cleanup_tweet(str(tweet))))\n",
    "#     return limpo\n",
    "# #lista para os tweets\n",
    "# test_tweets = []\n",
    "# for tweet in test['Teste']:\n",
    "#     test_tweets.append(limpando(tweet))\n",
    "\n",
    "# # Cria coluna de tweets limpos nos dados de teste\n",
    "# series_test = pd.Series(test_tweets)\n",
    "# test['Pr√© Processado'] = series_test\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compara(frase):\n",
    "    \"\"\"\n",
    "    Essa fun√ß√£o determina a taxa relativa referente a cada palavra de uma frase\n",
    "    para o c√°lculo da probabilidade condicional de Naive-Bayes, fazendo a\n",
    "    compara√ß√£o entre a probabilidade ser relevante ou irrelevante e retorna\n",
    "    a resposta (relevante ou irrelevante) com base na desigualdade.\n",
    "    \"\"\"\n",
    "    prob_nao_relevante=1\n",
    "    prob_relevante_positivo=1\n",
    "    prob_relevante_negativo=1\n",
    "\n",
    "    for palavra in frase:\n",
    "        if (palavra not in probs[0].index):\n",
    "            prob_nao_relevante *=1/(tot_n_rel+tol)\n",
    "        else: \n",
    "            prob_nao_relevante *= probs[0][palavra]\n",
    "        \n",
    "\n",
    "    for palavra in frase:\n",
    "        if (palavra not in probs[1].index):\n",
    "            prob_relevante_positivo *=1/(tot_pos+tol)\n",
    "        else:\n",
    "            prob_relevante_positivo *= probs[1][palavra]\n",
    "    for palavra in frase:\n",
    "        if (palavra not in probs[2].index):\n",
    "            prob_relevante_negativo *=1/(tot_neg+tol)\n",
    "        else:\n",
    "            prob_relevante_negativo *= probs[2][palavra]\n",
    "    \n",
    "    list_prob = [prob_nao_relevante,prob_relevante_positivo,prob_relevante_negativo]\n",
    "    index = list_prob.index(max(list_prob))\n",
    "    \n",
    "            \n",
    "    if index == 0:\n",
    "        return 'N√£o Relevante'\n",
    "    elif index==1:\n",
    "        return 'Relevante positiva'\n",
    "    elif index==2:\n",
    "        return 'Relevante negativa'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>N√£o Relevante</th>\n",
       "      <th>Relevante negativa</th>\n",
       "      <th>Relevante positiva</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevancia</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Relevante negativa</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N√£o relevante</th>\n",
       "      <td>0.31</td>\n",
       "      <td>50.46</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevante positiva</th>\n",
       "      <td>0.00</td>\n",
       "      <td>45.26</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Naive Bayes         N√£o Relevante  Relevante negativa  Relevante positiva\n",
       "Relevancia                                                               \n",
       "Relevante negativa           0.00                2.75                0.00\n",
       "N√£o relevante                0.31               50.46                0.31\n",
       "Relevante positiva           0.00               45.26                0.92"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def conclusao(coluna, linha):\n",
    "#     \"\"\"\n",
    "#     Aplica fun√ß√£o 'conclus√£o' para linha n da coluna do dataframe\n",
    "#     \"\"\"\n",
    "#     return compara(coluna[linha])\n",
    "\n",
    "# Para cada tweet de teste, aplica o modelo e compara com o r√≥tulo dado\n",
    "classificacao_modelo = []\n",
    "for i in range(0, len(test['Teste'])):\n",
    "    classificacao_modelo.append(compara(test['Pr√© Processado'][i]))\n",
    "    \n",
    "    \n",
    "\n",
    "# Cria coluna nos dados de teste com os resultados\n",
    "test[\"Naive Bayes\"] = classificacao_modelo\n",
    "\n",
    "# Exibe comparativo dos resultados do modelo com os r√≥tulos (em porcentagem)\n",
    "ct = pd.crosstab(test['Relevancia'], test['Naive Bayes'], normalize = True).round(4)*100\n",
    "ct\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-36-992ed1b6a8de>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-36-992ed1b6a8de>\"\u001b[1;36m, line \u001b[1;32m15\u001b[0m\n\u001b[1;33m    elif test['Relevancia'][i] == '' and test['Naive Bayes'][i] =get_ipython().getoutput(' 1:')\u001b[0m\n\u001b[1;37m                                                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "serie_0_test = test[test[\"Relevancia\"] == 'N√£o relevante']\n",
    "serie_1_test = test[test[\"Relevancia\"] =='Relevante positiva']\n",
    "serie_2_test=test[test['Relevancia']=='Relevante negativa']\n",
    "\n",
    "# Valores iniciais das quantidades de cada caso\n",
    "verdadeiros_positivos = 0\n",
    "falsos_positivos = 0\n",
    "verdadeiros_negativos = 0\n",
    "falsos_negativos = 0\n",
    "\n",
    "# Calcula a quantidade de tweets de cada um dos casos acima\n",
    "for i in range(len(test['Relevancia'])):\n",
    "    if test['Relevancia'][i] == 'N√£o relevante' and test['Naive Bayes'][i] == 'N√£o relevante':\n",
    "        verdadeiros_positivos += 1\n",
    "    elif test['Relevancia'][i] == 'N√£o relevante' and test['Naive Bayes'][i] =!'N√£o relevante' :\n",
    "        falsos_positivos += 1\n",
    "    elif test['Relevancia'][i] == 0 and test['Naive Bayes'][i] == 0:\n",
    "        verdadeiros_negativos += 1\n",
    "    elif test['Relevancia'][i] == 1 and test['Naive Bayes'][i] == 0:\n",
    "        falsos_negativos += 1\n",
    "\n",
    "# Retorna probabilidade para cada caso\n",
    "print(\"Contagem\\t\\tProbabilidade\")\n",
    "print(\"----------------------------------------\")\n",
    "print(\"%s:\\t\\t%f\" % ('Verdadeiros Positivos', verdadeiros_positivos/len(serie_1_test['Relevancia'])))\n",
    "print(\"%s:\\t\\t%f\" % ('Falsos Positivos', falsos_positivos/len(serie_0_test['Relevancia'])))\n",
    "print(\"%s:\\t\\t%f\" % ('Verdadeiros Negativos', verdadeiros_negativos/len(serie_0_test['Relevancia'])))\n",
    "print(\"%s:\\t\\t%f\" % ('Falsos Negativos', falsos_negativos/len(serie_1_test['Relevancia'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Definindo algumas fun√ß√µes necess√°rias ao processo\n",
    "\n",
    "# def laplace(quantidade_na_serie, total_serie, total):\n",
    "#     return (quantidade_na_serie + 1)/(total_serie + total)\n",
    "\n",
    "# def vezes_que_aparece(palavra, serie):\n",
    "#     \"\"\"\n",
    "#     Essa fun√ß√£o recebe uma determinada palavra e a s√©rie de palavras, \n",
    "#     retornando a quantidade de vezes que ela aparece na s√©rie\n",
    "#     \"\"\"\n",
    "#     quant = 0\n",
    "#     for tweet in serie:\n",
    "#         quant += tweet.count(palavra)\n",
    "#     return quant\n",
    "\n",
    "# def total_na_serie(serie):\n",
    "#     \"\"\"\n",
    "#     Essa fun√ß√£o retorna o total de palavras da s√©rie\n",
    "#     \"\"\"\n",
    "#     quant = 0\n",
    "#     for tweet in serie:\n",
    "#         quant += len(tweet)\n",
    "#     return quant\n",
    "\n",
    "# def lista_palavras(lista1, lista2,lista3):\n",
    "#     \"\"\"\n",
    "#     Essa fun√ß√£o retorna as palavras (sem repeti√ß√µes) presentes\n",
    "#     em cada uma das listas de entrada\n",
    "#     \"\"\"\n",
    "#     quant = []\n",
    "#     for tweet in lista1:\n",
    "#         for palavra in tweet:\n",
    "#             if palavra not in quant:\n",
    "#                 quant.append(palavra)                \n",
    "#     for tweet in lista2:\n",
    "#         for palavra in tweet:\n",
    "#             if palavra not in quant:\n",
    "#                 quant.append(palavra)\n",
    "#     for tweet in lista3:\n",
    "#             if palavra not in quant:\n",
    "#                 quant.append(palavra)\n",
    "#     return quant\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
