{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: __Alexandre Antar__\n",
    "\n",
    "Nome: __Gabriel de Araujo Alves__\n",
    "\n",
    "Nome: __Renato Laffranchi Falcao__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\users\\gabri\\anaconda3\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: wordcloud in c:\\users\\gabri\\anaconda3\\lib\\site-packages (1.8.1)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from wordcloud) (1.19.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from wordcloud) (8.0.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from wordcloud) (3.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2020.6.20)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.3.0)\n",
      "Requirement already satisfied: six in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji wordcloud\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from emoji import UNICODE_EMOJI\n",
    "import emoji\n",
    "import functools\n",
    "import operator\n",
    "import nltk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Users\\gabri\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\Projetos\\Projetos colaborativos\\Analise de sentimentos Twitter\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'brahma.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @sophiaecris: @marianaa2mari foi vcs crlh !...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@moraesbrunita pelo visto na mamadeira já era ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@purosucodosurto o cara não tem um pau tem um ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gente vcs que tão em home office a mais tempo ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @luciusnaweb: eu depois de dois latões de b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relevancia\n",
       "0  rt @sophiaecris: @marianaa2mari foi vcs crlh !...           0\n",
       "1  @moraesbrunita pelo visto na mamadeira já era ...           0\n",
       "2  @purosucodosurto o cara não tem um pau tem um ...           0\n",
       "3  gente vcs que tão em home office a mais tempo ...           1\n",
       "4  rt @luciusnaweb: eu depois de dois latões de b...           0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#base de treinamento\n",
    "train = pd.read_excel(filename, sheet_name = 'Treinamento')\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@elissanmanoel tão costurando brahma ? hahaha ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt @nayaralucas11: era só uma praia e brahma t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arrumando meu guarda roupa eis que encontro um...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>desceu foi whisky misturado c brahma kkkkkkkkk...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @carolaguiarcm: hj eu só queria estar numa ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Relevancia\n",
       "0  @elissanmanoel tão costurando brahma ? hahaha ...           0\n",
       "1  rt @nayaralucas11: era só uma praia e brahma t...           0\n",
       "2  arrumando meu guarda roupa eis que encontro um...           0\n",
       "3  desceu foi whisky misturado c brahma kkkkkkkkk...           0\n",
       "4  rt @carolaguiarcm: hj eu só queria estar numa ...           0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#base de teste\n",
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @sophiaecris: @marianaa2mari foi vcs crlh !...</td>\n",
       "      <td>Não relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@moraesbrunita pelo visto na mamadeira já era ...</td>\n",
       "      <td>Não relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@purosucodosurto o cara não tem um pau tem um ...</td>\n",
       "      <td>Não relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gente vcs que tão em home office a mais tempo ...</td>\n",
       "      <td>Relevante positiva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @luciusnaweb: eu depois de dois latões de b...</td>\n",
       "      <td>Não relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>acho q vou beber uma hj, desde domingo sem beb...</td>\n",
       "      <td>Relevante negativa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento          Relevancia\n",
       "0  rt @sophiaecris: @marianaa2mari foi vcs crlh !...       Não relevante\n",
       "1  @moraesbrunita pelo visto na mamadeira já era ...       Não relevante\n",
       "2  @purosucodosurto o cara não tem um pau tem um ...       Não relevante\n",
       "3  gente vcs que tão em home office a mais tempo ...  Relevante positiva\n",
       "4  rt @luciusnaweb: eu depois de dois latões de b...       Não relevante\n",
       "5  acho q vou beber uma hj, desde domingo sem beb...  Relevante negativa"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transformando variavel Relevancia em categórica\n",
    "train['Relevancia'] = train['Relevancia'].astype('category')\n",
    "\n",
    "train['Relevancia'].cat.categories = ['Relevante negativa', 'Não relevante', 'Relevante positiva']\n",
    "train.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separando o data frame por relevância do tweet\n",
    "nao_relevante=train[train.Relevancia=='Não relevante']\n",
    "relevante_positivo=train[train.Relevancia=='Relevante positiva']\n",
    "relevante_negativo=train[train.Relevancia=='Relevante negativa']\n",
    "classifica=[nao_relevante,relevante_positivo,relevante_negativo]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uma lista de strings para aferir a probabilidade posteriormente,não necessariamente será usada\n",
    "classifica_nao_relevante=str(list(classifica[0].Treinamento.values))\n",
    "classifica_positivo=str(list(classifica[1].Treinamento.values))\n",
    "classifica_negativo=str(list(classifica[2].Treinamento.values))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\n",
    "\n",
    "O produto escolhido foi a cerveja Brahma, uma marca nacional e bem popular de cerveja e a classificação dos tweets foram feitos da seguinte forma:\n",
    "\n",
    "* -1 : Relevante negativo -> Essa classificação se refere aos tweets que mecionavam o a marca de cerveja de forma negativa, seja com reclamações acerca do produto ou associando a marca à alguma experiência ruim.\n",
    "* 0 : Irrelevante -> Essa classificação se refere aos tweets que mecionavam o a marca de cerveja de forma neutra, sem reclamações ou elogios ao produto ou que não se referiram à cerveja.\n",
    "* 1 : Relevante positivo -> Essa classificação se refere aos tweets que mecionavam o a marca de cerveja de forma positiva, seja com elogios acerca do produto ou associando a marca à alguma experiência boa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1° etapa:Limpar tweets referentes ao treinamento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limpeza de mensagens em relação a pontuação\n",
    "#separação de emojis e palavras e separação entre emojis\n",
    "def cleanup_tweet(text):\n",
    "    punctuation = '[\\-/!.:?;,''\"@]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    text_subbed = re.sub(' +', ' ', text_subbed)\n",
    "    text_subbed = emoji.get_emoji_regexp().split(text_subbed)\n",
    "    separate = [text.split() for text in text_subbed]\n",
    "    text_subbed = functools.reduce(operator.concat, separate)\n",
    "    return text_subbed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remoção de outros items que não contarão para as relevâncias\n",
    "def remove_outros(items):\n",
    "    i=0\n",
    "    while(i<len(items)):\n",
    "        # Limpa '\\n'\n",
    "        items[i] = items[i].lower().replace('[\\n]', '')\n",
    "        \n",
    "        # Remove 'rt' de retweets\n",
    "        if items[i][0:2] == 'rt':\n",
    "            items[i] = items[i][3:]\n",
    "        \n",
    "        # Remove links\n",
    "        elif items[i][:4] == 'http':\n",
    "            del items[i]\n",
    "        i+=1\n",
    "            \n",
    "        \n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gabri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Remove 'stopwords' (preposições, artigos etc.) dos tweets\n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "stopwords.append('')\n",
    "\n",
    "# Define função que aplica remoção\n",
    "def remove_stopwords(lista):\n",
    "    removidos = lista[:]     \n",
    "    for palavra in lista: \n",
    "          if palavra in stopwords: \n",
    "                removidos.remove(palavra)               \n",
    "    return removidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#twt=cada tweet\n",
    "#aplica todas as funções anteriores para limpar as frases\n",
    "def limpos(classificador):\n",
    "    lis=[]\n",
    "    for twt in classificador.Treinamento:\n",
    "        lis.append(remove_stopwords(remove_outros(cleanup_tweet(twt))))\n",
    "    return lis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevancia</th>\n",
       "      <th>Treinamento_limpo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @sophiaecris: @marianaa2mari foi vcs crlh !...</td>\n",
       "      <td>Não relevante</td>\n",
       "      <td>sophiaecris, marianaa2mari, vcs, crlh, boa, br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@moraesbrunita pelo visto na mamadeira já era ...</td>\n",
       "      <td>Não relevante</td>\n",
       "      <td>moraesbrunita, visto, mamadeira, boa, brahma, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@purosucodosurto o cara não tem um pau tem um ...</td>\n",
       "      <td>Não relevante</td>\n",
       "      <td>purosucodosurto, cara, pau, latão, brahma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gente vcs que tão em home office a mais tempo ...</td>\n",
       "      <td>Relevante positiva</td>\n",
       "      <td>gente, vcs, tão, home, office, tempo, ok, mand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @luciusnaweb: eu depois de dois latões de b...</td>\n",
       "      <td>Não relevante</td>\n",
       "      <td>luciusnaweb, dois, latões, brahma, bem, assim,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento          Relevancia  \\\n",
       "0  rt @sophiaecris: @marianaa2mari foi vcs crlh !...       Não relevante   \n",
       "1  @moraesbrunita pelo visto na mamadeira já era ...       Não relevante   \n",
       "2  @purosucodosurto o cara não tem um pau tem um ...       Não relevante   \n",
       "3  gente vcs que tão em home office a mais tempo ...  Relevante positiva   \n",
       "4  rt @luciusnaweb: eu depois de dois latões de b...       Não relevante   \n",
       "\n",
       "                                   Treinamento_limpo  \n",
       "0  sophiaecris, marianaa2mari, vcs, crlh, boa, br...  \n",
       "1  moraesbrunita, visto, mamadeira, boa, brahma, ...  \n",
       "2          purosucodosurto, cara, pau, latão, brahma  \n",
       "3  gente, vcs, tão, home, office, tempo, ok, mand...  \n",
       "4  luciusnaweb, dois, latões, brahma, bem, assim,...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplica limpeza nas séries de cada classificação\n",
    "limpeza_tweets = [limpos(classifica[0]), limpos(classifica[1]),limpos(classifica[2])]\n",
    "\n",
    "# Limpa dados de treino\n",
    "limpeza = limpos(train)\n",
    "\n",
    "# Aplica listagem das palavras dos dados de treino\n",
    "for i in range(len(limpeza)):\n",
    "    limpeza[i] = ', '.join(limpeza[i])\n",
    "\n",
    "# Cria coluna com tweets já limpos\n",
    "train['Treinamento_limpo'] = limpeza\n",
    "\n",
    "\n",
    "\n",
    "train.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2° ETAPA\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "Agora com os dados limpos, o objetivo é ensinar o classificador de acordo com as probabilidades de cada palavra apresentada para cada série de relevância."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#value_counts-refere-se ao numero de vezes da palavra na série dos tweets não relevantes\n",
    "n_rel=train[train.Relevancia=='Não relevante']\n",
    "n_rel1=n_rel.Treinamento_limpo\n",
    "lista1=[]\n",
    "for tweet in n_rel1:\n",
    "    for palavra in tweet.split(','):\n",
    "        lista1.append(palavra)\n",
    "serie_n_rel=pd.Series(lista1).value_counts()\n",
    "tot_n_rel=serie_n_rel.sum() #total de palavras na respectiva série\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#value_counts-refere-se ao numero de vezes da palavra na série dos tweets relevantes positivos\n",
    "rel_pos=train[train.Relevancia=='Relevante positiva']\n",
    "rel_pos1=rel_pos.Treinamento_limpo\n",
    "lista2=[]\n",
    "for tweet in rel_pos1:\n",
    "    for palavra in tweet.split(','):\n",
    "        lista2.append(palavra)\n",
    "serie_pos=pd.Series(lista2).value_counts()\n",
    "tot_pos=serie_pos.sum() #total de palavras na respectiva série\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#value_counts-refere-se ao numero de vezes da palavra na série dos tweets relevantes negativos\n",
    "rel_neg=train[train.Relevancia=='Relevante negativa']\n",
    "rel_neg1=rel_neg.Treinamento_limpo\n",
    "lista3=[]\n",
    "for tweet in rel_neg1:\n",
    "    for palavra in tweet.split(','):\n",
    "        lista3.append(palavra)\n",
    "serie_neg=pd.Series(lista3).value_counts()\n",
    "tot_neg=serie_neg.sum() #total de palavras na respectiva série\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#listas 4 e 5 -referem-se respectivamente as palavras(index) e a contagem de cada palavra(values) na respectiva série\n",
    "lista4=[list(serie_n_rel.index),list(serie_pos.index),list(serie_neg.index)]\n",
    "lista5=[list(serie_n_rel.values),list(serie_pos.values),list(serie_neg.values)]\n",
    "#guarda as contagens de cada palavra em uma lista\n",
    "contagem=[]\n",
    "for i in range(len(lista4)):\n",
    "    dicio = {}\n",
    "    for j in range(len(lista4[i])):\n",
    "        dicio[lista4[i][j]]=lista5[i][j]\n",
    "    contagem.append(pd.Series(dicio))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2169"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retorna o total de palavras não repetidas em relacao as três classificações\n",
    "tol = (serie_n_rel + serie_pos + serie_neg).index.nunique()\n",
    "tol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3°etapa-LImpando a base de dados do teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevancia</th>\n",
       "      <th>Pré Processado</th>\n",
       "      <th>Naive Bayes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@elissanmanoel tão costurando brahma ? hahaha ...</td>\n",
       "      <td>Não relevante</td>\n",
       "      <td>[elissanmanoel, tão, costurando, brahma, hahah...</td>\n",
       "      <td>Relevante positiva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt @nayaralucas11: era só uma praia e brahma t...</td>\n",
       "      <td>Não relevante</td>\n",
       "      <td>[nayaralucas11, praia, brahma, trincando]</td>\n",
       "      <td>Relevante positiva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arrumando meu guarda roupa eis que encontro um...</td>\n",
       "      <td>Não relevante</td>\n",
       "      <td>[arrumando, guarda, roupa, eis, encontro, ling...</td>\n",
       "      <td>Não Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>desceu foi whisky misturado c brahma kkkkkkkkk...</td>\n",
       "      <td>Não relevante</td>\n",
       "      <td>[desceu, whisky, misturado, c, brahma, kkkkkkk...</td>\n",
       "      <td>Relevante positiva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @carolaguiarcm: hj eu só queria estar numa ...</td>\n",
       "      <td>Não relevante</td>\n",
       "      <td>[carolaguiarcm, hj, queria, estar, mesa, skol,...</td>\n",
       "      <td>Relevante positiva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vó beber brahma fodaze</td>\n",
       "      <td>Não relevante</td>\n",
       "      <td>[vó, beber, brahma, fodaze]</td>\n",
       "      <td>Relevante positiva</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste     Relevancia  \\\n",
       "0  @elissanmanoel tão costurando brahma ? hahaha ...  Não relevante   \n",
       "1  rt @nayaralucas11: era só uma praia e brahma t...  Não relevante   \n",
       "2  arrumando meu guarda roupa eis que encontro um...  Não relevante   \n",
       "3  desceu foi whisky misturado c brahma kkkkkkkkk...  Não relevante   \n",
       "4  rt @carolaguiarcm: hj eu só queria estar numa ...  Não relevante   \n",
       "5                             vó beber brahma fodaze  Não relevante   \n",
       "\n",
       "                                      Pré Processado         Naive Bayes  \n",
       "0  [elissanmanoel, tão, costurando, brahma, hahah...  Relevante positiva  \n",
       "1          [nayaralucas11, praia, brahma, trincando]  Relevante positiva  \n",
       "2  [arrumando, guarda, roupa, eis, encontro, ling...       Não Relevante  \n",
       "3  [desceu, whisky, misturado, c, brahma, kkkkkkk...  Relevante positiva  \n",
       "4  [carolaguiarcm, hj, queria, estar, mesa, skol,...  Relevante positiva  \n",
       "5                        [vó, beber, brahma, fodaze]  Relevante positiva  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def limpando(tweet):\n",
    "    return remove_stopwords(remove_outros(cleanup_tweet(str(tweet))))\n",
    "\n",
    "\n",
    "test_tweets = []\n",
    "for tweet in test['Teste']:\n",
    "    test_tweets.append(limpando(tweet))\n",
    "\n",
    "# Cria coluna de pré processados nos dados de teste\n",
    "series_test = pd.Series(test_tweets)\n",
    "test['Pré Processado'] = series_test\n",
    "\n",
    "#substitui a relevancia de numeros para categorias\n",
    "test['Relevancia'] = test['Relevancia'].astype('category')\n",
    "\n",
    "test['Relevancia'].cat.categories = ['Relevante negativa', 'Não relevante', 'Relevante positiva']\n",
    "test.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colocando as probabilidades de cada classe de relevancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela=train.Relevancia.value_counts()\n",
    "soma=train.Relevancia.value_counts().sum()\n",
    "n_rel=tabela[0]/soma\n",
    "rel_pos=tabela[1]/soma\n",
    "rel_neg=tabela[2]/soma\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4°etapa:Aplica a suavização de laplace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace(tweet):\n",
    "   \n",
    "    prob_nao_relevante=1\n",
    "    prob_relevante_positivo=1\n",
    "    prob_relevante_negativo=1\n",
    "    #suavização de laplace para a 1° série\n",
    "    for palavra in tweet:\n",
    "        if (palavra not in contagem[0].index):\n",
    "            prob_nao_relevante *=(1*n_rel)/(tot_n_rel+tol)\n",
    "        else: \n",
    "            prob_nao_relevante *= (contagem[0][palavra] + 1)*(n_rel)/(tot_n_rel+tol)\n",
    "        \n",
    "    #suavização de laplace para a 2° série\n",
    "    for palavra in tweet:\n",
    "        if (palavra not in contagem[1].index):\n",
    "            prob_relevante_positivo *=(1*rel_pos)/(tot_pos+tol)\n",
    "        else:\n",
    "            prob_relevante_positivo *= (contagem[1][palavra] + 1)/(tot_pos+tol)\n",
    "            \n",
    "     #suavização de laplace para a 3° série\n",
    "    for palavra in tweet:\n",
    "        if (palavra not in contagem[2].index):\n",
    "            prob_relevante_negativo *=(1*rel_neg)/(tot_neg+tol)\n",
    "        else:\n",
    "            prob_relevante_negativo *= (contagem[2][palavra] + 1)*(rel_neg)/(tot_neg+tol)\n",
    "            \n",
    "\n",
    "    #agrega as probabilidades de cada frase em uma lista e acha o máximo em relação aos 3 valores\n",
    "    list_prob = [prob_nao_relevante,prob_relevante_positivo,prob_relevante_negativo]\n",
    "    index = list_prob.index(max(list_prob))\n",
    "    \n",
    "    #retorna onde a frase se encaixa(Naive Bayes)       \n",
    "    if index == 0:\n",
    "        return 'Não Relevante'\n",
    "    elif index==1:\n",
    "        return 'Relevante positiva'\n",
    "    elif index==2:\n",
    "        return 'Relevante negativa'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>Não Relevante</th>\n",
       "      <th>Relevante positiva</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevancia</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Relevante negativa</th>\n",
       "      <td>0.31</td>\n",
       "      <td>2.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Não relevante</th>\n",
       "      <td>6.73</td>\n",
       "      <td>44.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevante positiva</th>\n",
       "      <td>2.75</td>\n",
       "      <td>43.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Naive Bayes         Não Relevante  Relevante positiva\n",
       "Relevancia                                           \n",
       "Relevante negativa           0.31                2.45\n",
       "Não relevante                6.73               44.34\n",
       "Relevante positiva           2.75               43.43"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para cada tweet de teste, aplica o modelo e compara com o rótulo dado\n",
    "classificacao_modelo = []\n",
    "for i in range(0, len(test['Teste'])):\n",
    "    classificacao_modelo.append(laplace(test['Pré Processado'][i]))\n",
    "    \n",
    "    \n",
    "\n",
    "# Cria coluna nos dados de teste com os resultados\n",
    "test[\"Naive Bayes\"] = classificacao_modelo\n",
    "\n",
    "# Exibe comparativo dos resultados do modelo com os rótulos (em porcentagem)\n",
    "ct = pd.crosstab(test['Relevancia'], test['Naive Bayes'], normalize = True).round(4)*100\n",
    "ct\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contagem\t\tProbabilidade (em %)\n",
      "----------------------------------------\n",
      "Verdadeiros Não Relevantes:\t0.000000\n",
      "Falsos Não Relevantes:\t\t100.000000\n",
      "Verdadeiros Positivos:\t\t94.039735\n",
      "Falsos Positivos:\t\t5.960265\n",
      "Verdadeiros Negativos:\t\t0.000000\n",
      "Falsos Negativos:\t\t100.000000\n"
     ]
    }
   ],
   "source": [
    "serie_0_test = test[test[\"Relevancia\"] == 'Não relevante']\n",
    "serie_1_test = test[test[\"Relevancia\"] == 'Relevante positiva']\n",
    "serie_2_test = test[test['Relevancia'] == 'Relevante negativa']\n",
    "\n",
    "# Valores iniciais das quantidades de cada caso\n",
    "verdadeiros_naorelevantes = 0\n",
    "falsos_naorelevantes = 0\n",
    "verdadeiros_positivos = 0\n",
    "falsos_positivos = 0\n",
    "verdadeiros_negativos = 0\n",
    "falsos_negativos = 0\n",
    "\n",
    "# Calcula a quantidade de tweets de cada um dos casos acima\n",
    "for i in range(len(test['Relevancia'])):\n",
    "    if test['Relevancia'][i] == 'Não relevante' and test['Naive Bayes'][i] == 'Não relevante':\n",
    "        verdadeiros_naorelevantes += 1\n",
    "    elif test['Relevancia'][i] == 'Não relevante' and test['Naive Bayes'][i] != 'Não relevante':\n",
    "        falsos_naorelevantes += 1\n",
    "    elif test['Relevancia'][i] == 'Relevante positiva' and test['Naive Bayes'][i] == 'Relevante positiva':\n",
    "        verdadeiros_positivos += 1\n",
    "    elif test['Relevancia'][i] == 'Relevante positiva' and test['Naive Bayes'][i] != 'Relevante positiva':\n",
    "        falsos_positivos += 1\n",
    "    elif test['Relevancia'][i] == 'Relevante negativa' and test['Naive Bayes'][i] == 'Relevante negativa':\n",
    "        verdadeiros_negativos += 1\n",
    "    elif test['Relevancia'][i] == 'Relevante negativa' and test['Naive Bayes'][i] != 'Relevante negativa':\n",
    "        falsos_negativos += 1\n",
    "    \n",
    "    \n",
    "\n",
    "# Retorna probabilidade para cada caso\n",
    "print(\"Contagem\\t\\tProbabilidade (em %)\")\n",
    "print(\"----------------------------------------\")\n",
    "print(\"%s:\\t%f\" % ('Verdadeiros Não Relevantes', (verdadeiros_naorelevantes/len(serie_0_test['Relevancia'])*100)))\n",
    "print(\"%s:\\t\\t%f\" % ('Falsos Não Relevantes', (falsos_naorelevantes/len(serie_0_test['Relevancia'])*100)))\n",
    "print(\"%s:\\t\\t%f\" % ('Verdadeiros Positivos', (verdadeiros_positivos/len(serie_1_test['Relevancia'])*100)))\n",
    "print(\"%s:\\t\\t%f\" % ('Falsos Positivos', (falsos_positivos/len(serie_1_test['Relevancia'])*100)))\n",
    "print(\"%s:\\t\\t%f\" % ('Verdadeiros Negativos', (verdadeiros_negativos/len(serie_2_test['Relevancia'])*100)))\n",
    "print(\"%s:\\t\\t%f\" % ('Falsos Negativos', (falsos_negativos/len(serie_2_test['Relevancia'])*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acordo com os resultados obtidos pelo classificador e pelo cálculo das probabilidades, chegamos a conclusão que o classificador desenvolvido a partir da planilha de Testes do Excel não é exato para a classificação dos tweets em questão de relevância. Isso se deve ao fato de os classificados como Relevantes positivos na planilha Treinamento excedem em grande quantidade as outras categorias. Tendo isso em vista, pensando nos tweets negativos, obtivemos um pequeno numero de amostras e, portanto, o classificador teve uma exatidão maior. Por outro lado, tendo em vista os tweets positivos, como o numero de amostras foi maior, o classificador teve uma exatidão menor. Além disso não foi observada grande uniformidade entre a coleta de dados referente ao treinamento e a coleta de dados referente ao teste. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "### Como melhorar o modelo? \n",
    "\n",
    "Pode-se melhorar o desempenho do classificador com algumas práticas:\n",
    "\n",
    "- **Aumentar o banco de dados de treinamento com mais tweets**<br>\n",
    "Para um número maior de tweets obtem-se maior variedade de palavras e,dessa maneira,maior distribuição de probabilidades para cada palavra.Na parte de obtenção de dados o aumento do número de palavras buscadas no treinamento e teste pode ser uma solução para a melhora desse ponto.\n",
    "\n",
    "- **Melhorar classificação dos tweets**<br>\n",
    "Após a coleta de tweets o grupo obteve muitas palavras e após a análise de sentimentos em relação a cada tweet o número de tweets relevantes positivos foi em ,grande medida, dominante em relação as outras categorias e influenciou na precisão de falsos e verdadeiros obtidos posteriormente.Logo,melhorar a análise de sentimentos e fundamental para a soluçõa do ponto citado\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
