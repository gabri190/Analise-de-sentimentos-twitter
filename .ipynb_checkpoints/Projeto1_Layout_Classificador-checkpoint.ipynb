{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: __Alexandre Antar__\n",
    "\n",
    "Nome: __Gabriel de Araujo Alves__\n",
    "\n",
    "Nome: __Renato Laffranchi Falcao__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\users\\pc\\anaconda3\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: wordcloud in c:\\users\\pc\\anaconda3\\lib\\site-packages (1.8.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\pc\\anaconda3\\lib\\site-packages (from wordcloud) (3.2.2)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from wordcloud) (1.18.5)\n",
      "Requirement already satisfied: pillow in c:\\users\\pc\\anaconda3\\lib\\site-packages (from wordcloud) (7.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from python-dateutil>=2.1->matplotlib->wordcloud) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji wordcloud\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from emoji import UNICODE_EMOJI\n",
    "import emoji\n",
    "import functools\n",
    "import operator\n",
    "import nltk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Users\\PC\\Desktop\\2 SEMESTRE\\CDADOS\\Projeto 1\\Project1\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'brahma.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @sophiaecris: @marianaa2mari foi vcs crlh !...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@moraesbrunita pelo visto na mamadeira já era ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@purosucodosurto o cara não tem um pau tem um ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gente vcs que tão em home office a mais tempo ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @luciusnaweb: eu depois de dois latões de b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relevancia\n",
       "0  rt @sophiaecris: @marianaa2mari foi vcs crlh !...           0\n",
       "1  @moraesbrunita pelo visto na mamadeira já era ...           0\n",
       "2  @purosucodosurto o cara não tem um pau tem um ...           0\n",
       "3  gente vcs que tão em home office a mais tempo ...           1\n",
       "4  rt @luciusnaweb: eu depois de dois latões de b...           0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#base de treinamento\n",
    "train = pd.read_excel(filename, sheet_name = 'Treinamento')\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@elissanmanoel tão costurando brahma ? hahaha ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt @nayaralucas11: era só uma praia e brahma t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arrumando meu guarda roupa eis que encontro um...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>desceu foi whisky misturado c brahma kkkkkkkkk...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @carolaguiarcm: hj eu só queria estar numa ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Relevancia\n",
       "0  @elissanmanoel tão costurando brahma ? hahaha ...           0\n",
       "1  rt @nayaralucas11: era só uma praia e brahma t...           0\n",
       "2  arrumando meu guarda roupa eis que encontro um...           0\n",
       "3  desceu foi whisky misturado c brahma kkkkkkkkk...           0\n",
       "4  rt @carolaguiarcm: hj eu só queria estar numa ...           0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#base de teste\n",
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @sophiaecris: @marianaa2mari foi vcs crlh !...</td>\n",
       "      <td>Não relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@moraesbrunita pelo visto na mamadeira já era ...</td>\n",
       "      <td>Não relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@purosucodosurto o cara não tem um pau tem um ...</td>\n",
       "      <td>Não relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gente vcs que tão em home office a mais tempo ...</td>\n",
       "      <td>Relevante positiva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @luciusnaweb: eu depois de dois latões de b...</td>\n",
       "      <td>Não relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>acho q vou beber uma hj, desde domingo sem beb...</td>\n",
       "      <td>Relevante negativa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento          Relevancia\n",
       "0  rt @sophiaecris: @marianaa2mari foi vcs crlh !...       Não relevante\n",
       "1  @moraesbrunita pelo visto na mamadeira já era ...       Não relevante\n",
       "2  @purosucodosurto o cara não tem um pau tem um ...       Não relevante\n",
       "3  gente vcs que tão em home office a mais tempo ...  Relevante positiva\n",
       "4  rt @luciusnaweb: eu depois de dois latões de b...       Não relevante\n",
       "5  acho q vou beber uma hj, desde domingo sem beb...  Relevante negativa"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transformando variavel Relevancia em categórica\n",
    "train['Relevancia'] = train['Relevancia'].astype('category')\n",
    "\n",
    "train['Relevancia'].cat.categories = ['Relevante negativa', 'Não relevante', 'Relevante positiva']\n",
    "train.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separando o data frame por relevância do tweet\n",
    "nao_relevante=train[train.Relevancia=='Não relevante']\n",
    "relevante_positivo=train[train.Relevancia=='Relevante positiva']\n",
    "relevante_negativo=train[train.Relevancia=='Relevante negativa']\n",
    "classifica=[nao_relevante,relevante_positivo,relevante_negativo]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uma lista de strings para aferir a probabilidade posteriormente,não necessariamente será usada\n",
    "classifica_nao_relevante=str(list(classifica[0].Treinamento.values))\n",
    "classifica_positivo=str(list(classifica[1].Treinamento.values))\n",
    "classifica_negativo=str(list(classifica[2].Treinamento.values))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\n",
    "\n",
    "O produto escolhido foi a cerveja Brahma, uma marca nacional e bem popular de cerveja e a classificação dos tweets foram feitos da seguinte forma:\n",
    "\n",
    "* -1 : Relevante negativo -> Essa classificação se refere aos tweets que mecionavam o a marca de cerveja de forma negativa, seja com reclamações acerca do produto ou associando a marca à alguma experiência ruim.\n",
    "* 0 : Irrelevante -> Essa classificação se refere aos tweets que mecionavam o a marca de cerveja de forma neutra, sem reclamações ou elogios ao produto ou que não se referiram à cerveja.\n",
    "* 1 : Relevante positivo -> Essa classificação se refere aos tweets que mecionavam o a marca de cerveja de forma positiva, seja com elogios acerca do produto ou associando a marca à alguma experiência boa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limpeza de mensagens em relação a pontuação\n",
    "def cleanup_tweet(text):\n",
    "    punctuation = '[\\-/!.:?;,''\"@]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    text_subbed = re.sub(' +', ' ', text_subbed)\n",
    "    text_subbed = emoji.get_emoji_regexp().split(text_subbed)\n",
    "    separate = [text.split() for text in text_subbed]\n",
    "    text_subbed = functools.reduce(operator.concat, separate)\n",
    "    return text_subbed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remoção de outros items que não contarão para as relevâncias\n",
    "def remove_outros(items):\n",
    "    i=0\n",
    "    while(i<len(items)):\n",
    "        # Limpa '\\n'\n",
    "        items[i] = items[i].lower().replace('[\\n]', '')\n",
    "        \n",
    "        # Remove 'rt' de retweets\n",
    "        if items[i][0:2] == 'rt':\n",
    "            items[i] = items[i][3:]\n",
    "        \n",
    "        # Remove links\n",
    "        elif items[i][:4] == 'http':\n",
    "            del items[i]\n",
    "        i+=1\n",
    "            \n",
    "        \n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Remove 'stopwords' (preposições, artigos etc.) dos tweets\n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "stopwords.append('')\n",
    "\n",
    "# Define função que aplica remoção\n",
    "def remove_stopwords(lista):\n",
    "    filtrada = lista[:]     \n",
    "    for palavra in lista: \n",
    "          if palavra in stopwords: \n",
    "                filtrada.remove(palavra)               \n",
    "    return filtrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#twt=cada tweet\n",
    "#aplica todas as funções anteriores para limpar as frases\n",
    "def limpos(classificador):\n",
    "    lis=[]\n",
    "    for twt in classificador.Treinamento:\n",
    "        lis.append(remove_stopwords(remove_outros(cleanup_tweet(twt))))\n",
    "    return lis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevancia</th>\n",
       "      <th>Treinamento_limpo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @sophiaecris: @marianaa2mari foi vcs crlh !...</td>\n",
       "      <td>Não relevante</td>\n",
       "      <td>sophiaecris, marianaa2mari, vcs, crlh, boa, br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@moraesbrunita pelo visto na mamadeira já era ...</td>\n",
       "      <td>Não relevante</td>\n",
       "      <td>moraesbrunita, visto, mamadeira, boa, brahma, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@purosucodosurto o cara não tem um pau tem um ...</td>\n",
       "      <td>Não relevante</td>\n",
       "      <td>purosucodosurto, cara, pau, latão, brahma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gente vcs que tão em home office a mais tempo ...</td>\n",
       "      <td>Relevante positiva</td>\n",
       "      <td>gente, vcs, tão, home, office, tempo, ok, mand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @luciusnaweb: eu depois de dois latões de b...</td>\n",
       "      <td>Não relevante</td>\n",
       "      <td>luciusnaweb, dois, latões, brahma, bem, assim,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento          Relevancia  \\\n",
       "0  rt @sophiaecris: @marianaa2mari foi vcs crlh !...       Não relevante   \n",
       "1  @moraesbrunita pelo visto na mamadeira já era ...       Não relevante   \n",
       "2  @purosucodosurto o cara não tem um pau tem um ...       Não relevante   \n",
       "3  gente vcs que tão em home office a mais tempo ...  Relevante positiva   \n",
       "4  rt @luciusnaweb: eu depois de dois latões de b...       Não relevante   \n",
       "\n",
       "                                   Treinamento_limpo  \n",
       "0  sophiaecris, marianaa2mari, vcs, crlh, boa, br...  \n",
       "1  moraesbrunita, visto, mamadeira, boa, brahma, ...  \n",
       "2          purosucodosurto, cara, pau, latão, brahma  \n",
       "3  gente, vcs, tão, home, office, tempo, ok, mand...  \n",
       "4  luciusnaweb, dois, latões, brahma, bem, assim,...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplica limpeza nas séries de cada classificação\n",
    "limpeza_tweets = [limpos(classifica[0]), limpos(classifica[1]),limpos(classifica[2])]\n",
    "\n",
    "# Limpa dados de treino\n",
    "limpeza = limpos(train)\n",
    "\n",
    "# Aplica listagem das palavras dos dados de treino\n",
    "for i in range(len(limpeza)):\n",
    "    limpeza[i] = ', '.join(limpeza[i])\n",
    "\n",
    "# Cria coluna com tweets já limpos\n",
    "train['Treinamento_limpo'] = limpeza\n",
    "\n",
    "\n",
    "\n",
    "train.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2° ETAPA\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "Agora com os dados limpos, o objetivo é ensinar o classificador de acordo com as porbabilidades de cada palavra apresentada para cada série de relevância."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1327"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#value_counts em relação aos tweets irrelevantes,assim o pd_series afere todas as probabilidades por palavra nessa série\n",
    "n_rel=train[train.Relevancia=='Não relevante']\n",
    "n_rel1=n_rel.Treinamento_limpo\n",
    "lista1=[]\n",
    "for tweet in n_rel1:\n",
    "    for palavra in tweet.split(','):\n",
    "        lista1.append(palavra)\n",
    "serie_n_rel=pd.Series(lista1).value_counts()\n",
    "tot_n_rel=len(serie_n_rel)\n",
    "tot_n_rel\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1108"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#value_counts em relação aos tweets relevantes positivos,assim o pd_series afere todas as probabilidades por palavra nessa série\n",
    "rel_pos=train[train.Relevancia=='Relevante positiva']\n",
    "rel_pos1=rel_pos.Treinamento_limpo\n",
    "lista2=[]\n",
    "for tweet in rel_pos1:\n",
    "    for palavra in tweet.split(','):\n",
    "        lista2.append(palavra)\n",
    "serie_pos=pd.Series(lista2).value_counts()\n",
    "tot_pos=len(serie_pos)\n",
    "tot_pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " brahma     24\n",
       "brahma       6\n",
       " dor         5\n",
       " 🤤           5\n",
       " dia         4\n",
       "            ..\n",
       " merda       1\n",
       " ter         1\n",
       "dois         1\n",
       " receita     1\n",
       " vou         1\n",
       "Length: 170, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#value_counts em relação aos tweets relevantes negativos,assim o pd_series afere todas as probabilidades por palavra nessa série\n",
    "rel_neg=train[train.Relevancia=='Relevante negativa']\n",
    "rel_neg1=rel_neg.Treinamento_limpo\n",
    "lista3=[]\n",
    "for tweet in rel_neg1:\n",
    "    for palavra in tweet.split(','):\n",
    "        lista3.append(palavra)\n",
    "serie_neg=pd.Series(lista3).value_counts()\n",
    "tot_neg=len(serie_neg)\n",
    "tot_neg\n",
    "serie_neg\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lista4=[list(serie_n_rel.index),list(serie_pos.index),list(serie_neg.index)]\n",
    "lista5=[list(serie_n_rel.values),list(serie_pos.values),list(serie_neg.values)]\n",
    "\n",
    "probs=[]\n",
    "for i in range(len(lista4)):\n",
    "    dicio = {}\n",
    "    for j in range(len(lista4[i])):\n",
    "        dicio[lista4[i][j]]=lista5[i][j]\n",
    "    probs.append(pd.Series(dicio))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista para as palavras não repetidas\n",
    "def repetidas(lista1, lista2,lista3):\n",
    "    qtd = []\n",
    "    for tweet in lista1:\n",
    "        for palavra in tweet:\n",
    "            if palavra not in qtd:\n",
    "                qtd.append(palavra)                \n",
    "    for tweet in lista2:\n",
    "        for palavra in tweet:\n",
    "            if palavra not in qtd:\n",
    "                qtd.append(palavra)\n",
    "    for tweet in lista3:\n",
    "        for palavra in tweet:\n",
    "            if palavra not in qtd:\n",
    "                qtd.append(palavra)\n",
    "    return qtd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2169"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retorna o total de palavras não repetidas em relacao as três classificações\n",
    "tol = (serie_n_rel + serie_pos + serie_neg).index.nunique()\n",
    "tol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevancia</th>\n",
       "      <th>Pré Processado</th>\n",
       "      <th>Naive Bayes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@elissanmanoel tão costurando brahma ? hahaha ...</td>\n",
       "      <td>Não relevante</td>\n",
       "      <td>[elissanmanoel, tão, costurando, brahma, hahah...</td>\n",
       "      <td>Relevante negativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt @nayaralucas11: era só uma praia e brahma t...</td>\n",
       "      <td>Não relevante</td>\n",
       "      <td>[nayaralucas11, praia, brahma, trincando]</td>\n",
       "      <td>Relevante negativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arrumando meu guarda roupa eis que encontro um...</td>\n",
       "      <td>Não relevante</td>\n",
       "      <td>[arrumando, guarda, roupa, eis, encontro, ling...</td>\n",
       "      <td>Relevante negativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>desceu foi whisky misturado c brahma kkkkkkkkk...</td>\n",
       "      <td>Não relevante</td>\n",
       "      <td>[desceu, whisky, misturado, c, brahma, kkkkkkk...</td>\n",
       "      <td>Relevante negativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @carolaguiarcm: hj eu só queria estar numa ...</td>\n",
       "      <td>Não relevante</td>\n",
       "      <td>[carolaguiarcm, hj, queria, estar, mesa, skol,...</td>\n",
       "      <td>Relevante negativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vó beber brahma fodaze</td>\n",
       "      <td>Não relevante</td>\n",
       "      <td>[vó, beber, brahma, fodaze]</td>\n",
       "      <td>Relevante negativa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste     Relevancia  \\\n",
       "0  @elissanmanoel tão costurando brahma ? hahaha ...  Não relevante   \n",
       "1  rt @nayaralucas11: era só uma praia e brahma t...  Não relevante   \n",
       "2  arrumando meu guarda roupa eis que encontro um...  Não relevante   \n",
       "3  desceu foi whisky misturado c brahma kkkkkkkkk...  Não relevante   \n",
       "4  rt @carolaguiarcm: hj eu só queria estar numa ...  Não relevante   \n",
       "5                             vó beber brahma fodaze  Não relevante   \n",
       "\n",
       "                                      Pré Processado         Naive Bayes  \n",
       "0  [elissanmanoel, tão, costurando, brahma, hahah...  Relevante negativa  \n",
       "1          [nayaralucas11, praia, brahma, trincando]  Relevante negativa  \n",
       "2  [arrumando, guarda, roupa, eis, encontro, ling...  Relevante negativa  \n",
       "3  [desceu, whisky, misturado, c, brahma, kkkkkkk...  Relevante negativa  \n",
       "4  [carolaguiarcm, hj, queria, estar, mesa, skol,...  Relevante negativa  \n",
       "5                        [vó, beber, brahma, fodaze]  Relevante negativa  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def limpando(tweet):\n",
    "    limpo = remove_stopwords(remove_outros(cleanup_tweet(str(tweet))))\n",
    "    return limpo\n",
    "\n",
    "test_tweets = []\n",
    "for tweet in test['Teste']:\n",
    "    test_tweets.append(limpando(tweet))\n",
    "\n",
    "# Cria coluna de pré processados nos dados de teste\n",
    "series_test = pd.Series(test_tweets)\n",
    "test['Pré Processado'] = series_test\n",
    "\n",
    "#substitui a relevancia de numeros para categorias\n",
    "test['Relevancia'] = test['Relevancia'].astype('category')\n",
    "\n",
    "test['Relevancia'].cat.categories = ['Relevante negativa', 'Não relevante', 'Relevante positiva']\n",
    "test.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compara(frase):\n",
    "    \"\"\"\n",
    "    Essa função determina a taxa relativa referente a cada palavra de uma frase\n",
    "    para o cálculo da probabilidade condicional de Naive-Bayes, fazendo a\n",
    "    comparação entre a probabilidade ser relevante ou irrelevante e retorna\n",
    "    a resposta (relevante ou irrelevante) com base na desigualdade.\n",
    "    \"\"\"\n",
    "    prob_nao_relevante=1\n",
    "    prob_relevante_positivo=1\n",
    "    prob_relevante_negativo=1\n",
    "\n",
    "    for palavra in frase:\n",
    "        if (palavra not in probs[0].index):\n",
    "            prob_nao_relevante *=1/(tot_n_rel+tol)\n",
    "        else: \n",
    "            prob_nao_relevante *= (probs[0][palavra] + 1)/(tot_n_rel+tol)\n",
    "        \n",
    "\n",
    "    for palavra in frase:\n",
    "        if (palavra not in probs[1].index):\n",
    "            prob_relevante_positivo *=1/(tot_pos+tol)\n",
    "        else:\n",
    "            prob_relevante_positivo *= (probs[1][palavra] + 1)/(tot_pos+tol)\n",
    "            \n",
    "\n",
    "    for palavra in frase:\n",
    "        if (palavra not in probs[2].index):\n",
    "            prob_relevante_negativo *=1/(tot_neg+tol)\n",
    "        else:\n",
    "            prob_relevante_negativo *= (probs[2][palavra] + 1)/(tot_neg+tol)\n",
    "            \n",
    "\n",
    "    \n",
    "    list_prob = [prob_nao_relevante,prob_relevante_positivo,prob_relevante_negativo]\n",
    "    index = list_prob.index(max(list_prob))\n",
    "    \n",
    "            \n",
    "    if index == 0:\n",
    "        return 'Não Relevante'\n",
    "    elif index==1:\n",
    "        return 'Relevante positiva'\n",
    "    elif index==2:\n",
    "        return 'Relevante negativa'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>Não Relevante</th>\n",
       "      <th>Relevante negativa</th>\n",
       "      <th>Relevante positiva</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevancia</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Relevante negativa</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Não relevante</th>\n",
       "      <td>0.31</td>\n",
       "      <td>43.12</td>\n",
       "      <td>7.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevante positiva</th>\n",
       "      <td>0.00</td>\n",
       "      <td>28.75</td>\n",
       "      <td>17.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Naive Bayes         Não Relevante  Relevante negativa  Relevante positiva\n",
       "Relevancia                                                               \n",
       "Relevante negativa           0.00                2.45                0.31\n",
       "Não relevante                0.31               43.12                7.65\n",
       "Relevante positiva           0.00               28.75               17.43"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para cada tweet de teste, aplica o modelo e compara com o rótulo dado\n",
    "classificacao_modelo = []\n",
    "for i in range(0, len(test['Teste'])):\n",
    "    classificacao_modelo.append(compara(test['Pré Processado'][i]))\n",
    "    \n",
    "    \n",
    "\n",
    "# Cria coluna nos dados de teste com os resultados\n",
    "test[\"Naive Bayes\"] = classificacao_modelo\n",
    "\n",
    "# Exibe comparativo dos resultados do modelo com os rótulos (em porcentagem)\n",
    "ct = pd.crosstab(test['Relevancia'], test['Naive Bayes'], normalize = True).round(4)*100\n",
    "ct\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contagem\t\tProbabilidade (em %)\n",
      "----------------------------------------\n",
      "Verdadeiros Não Relevantes:\t0.000000\n",
      "Falsos Não Relevantes:\t\t100.000000\n",
      "Verdadeiros Positivos:\t\t37.748344\n",
      "Falsos Positivos:\t\t62.251656\n",
      "Verdadeiros Negativos:\t\t88.888889\n",
      "Falsos Negativos:\t\t11.111111\n"
     ]
    }
   ],
   "source": [
    "serie_0_test = test[test[\"Relevancia\"] == 'Não relevante']\n",
    "serie_1_test = test[test[\"Relevancia\"] == 'Relevante positiva']\n",
    "serie_2_test = test[test['Relevancia'] == 'Relevante negativa']\n",
    "\n",
    "# Valores iniciais das quantidades de cada caso\n",
    "verdadeiros_naorelevantes = 0\n",
    "falsos_naorelevantes = 0\n",
    "verdadeiros_positivos = 0\n",
    "falsos_positivos = 0\n",
    "verdadeiros_negativos = 0\n",
    "falsos_negativos = 0\n",
    "\n",
    "# Calcula a quantidade de tweets de cada um dos casos acima\n",
    "for i in range(len(test['Relevancia'])):\n",
    "    if test['Relevancia'][i] == 'Não relevante' and test['Naive Bayes'][i] == 'Não relevante':\n",
    "        verdadeiros_naorelevantes += 1\n",
    "    elif test['Relevancia'][i] == 'Não relevante' and test['Naive Bayes'][i] != 'Não relevante':\n",
    "        falsos_naorelevantes += 1\n",
    "    elif test['Relevancia'][i] == 'Relevante positiva' and test['Naive Bayes'][i] == 'Relevante positiva':\n",
    "        verdadeiros_positivos += 1\n",
    "    elif test['Relevancia'][i] == 'Relevante positiva' and test['Naive Bayes'][i] != 'Relevante positiva':\n",
    "        falsos_positivos += 1\n",
    "    elif test['Relevancia'][i] == 'Relevante negativa' and test['Naive Bayes'][i] == 'Relevante negativa':\n",
    "        verdadeiros_negativos += 1\n",
    "    elif test['Relevancia'][i] == 'Relevante negativa' and test['Naive Bayes'][i] != 'Relevante negativa':\n",
    "        falsos_negativos += 1\n",
    "    \n",
    "    \n",
    "\n",
    "# Retorna probabilidade para cada caso\n",
    "print(\"Contagem\\t\\tProbabilidade (em %)\")\n",
    "print(\"----------------------------------------\")\n",
    "print(\"%s:\\t%f\" % ('Verdadeiros Não Relevantes', (verdadeiros_naorelevantes/len(serie_0_test['Relevancia'])*100)))\n",
    "print(\"%s:\\t\\t%f\" % ('Falsos Não Relevantes', (falsos_naorelevantes/len(serie_0_test['Relevancia'])*100)))\n",
    "print(\"%s:\\t\\t%f\" % ('Verdadeiros Positivos', (verdadeiros_positivos/len(serie_1_test['Relevancia'])*100)))\n",
    "print(\"%s:\\t\\t%f\" % ('Falsos Positivos', (falsos_positivos/len(serie_1_test['Relevancia'])*100)))\n",
    "print(\"%s:\\t\\t%f\" % ('Verdadeiros Negativos', (verdadeiros_negativos/len(serie_2_test['Relevancia'])*100)))\n",
    "print(\"%s:\\t\\t%f\" % ('Falsos Negativos', (falsos_negativos/len(serie_2_test['Relevancia'])*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acordo com os resultados obtidos pelo classificador e pelo cálculo das probabilidades, chegamos a conclusão que o classificador desenvolvido a partir da planilha de Testes do Excel não é exato para a classificação dos tweets em questão de relevância. Isso se deve ao fato de os classificados como Relevantes positivos na planilha Treinamento excedem em grande quantidade as outras categorias. Tendo isso em vista, pensando nos tweets negativos, obtivemos um pequeno numero de amostras e, portanto, o classificador teve uma exatidão maior. Por outro lado, tendo em vista os tweets positivos, como o numero de amostras foi maior, o classificador teve uma exatidão menor. Além disso não foi observada grande uniformidade entre a coleta de dados referente ao treinamento e a coleta de dados referente ao teste. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
